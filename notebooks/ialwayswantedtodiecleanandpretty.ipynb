{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "atHtXCxQo2QH",
        "-JwSpKEEpI5X",
        "P6AJTnmvpXkB",
        "F7rHThAbpk0A"
      ],
      "mount_file_id": "1UgVk3HYl1ojN4_YoFcdg-G7UeoNAZJbf",
      "authorship_tag": "ABX9TyOwMnowx/EmytiDUtXW92YD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reckn/super-disco/blob/main/ialwayswantedtodiecleanandpretty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product Recommendation using Matrix Factorization ðŸ›ï¸\n",
        "\n",
        "### Overview\n",
        "This code implements a recommendation system using matrix factorization, specifically Singular Value Decomposition (SVD). It predicts user-item interactions based on purchase history and product details, then recommends top products for a given user.\n",
        "\n",
        "### Functions Explained:\n",
        "\n",
        "#### 1. Load Datasets\n",
        "   - **Purpose**: Load customer interactions, purchase history, and product details datasets from CSV files.\n",
        "   - **Inputs**: None.\n",
        "   - **Output**: DataFrames `interactions`, `purchase_history`, and `product_details`.\n",
        "\n",
        "#### 2. Preprocess Data\n",
        "   - **Purpose**: Merge datasets to create a unified dataset and prepare it for matrix factorization.\n",
        "   - **Inputs**: Purchase history and product details DataFrames.\n",
        "   - **Output**: User-item matrix (`user_item_matrix`) and sparse matrix representation (`user_item_sparse`).\n",
        "\n",
        "#### 3. Decompose Matrix using SVD\n",
        "   - **Purpose**: Decompose the user-item matrix using Singular Value Decomposition (SVD) to extract latent factors.\n",
        "   - **Inputs**: Sparse user-item matrix and the number of latent factors (`k`).\n",
        "   - **Output**: Decomposed matrices `U`, `sigma`, and `Vt`.\n",
        "\n",
        "#### 4. Make Predictions\n",
        "   - **Purpose**: Reconstruct the user-item matrix using the decomposed matrices to make predictions.\n",
        "   - **Inputs**: Decomposed matrices `U`, `sigma`, and `Vt`.\n",
        "   - **Output**: Predicted ratings for all user-item interactions.\n",
        "\n",
        "#### 5. Recommend Products\n",
        "   - **Purpose**: Generate top product recommendations for a given user based on predicted ratings.\n",
        "   - **Inputs**: User ID and number of recommendations (`num_recommendations`).\n",
        "   - **Output**: DataFrame containing top recommended products for the user.\n",
        "\n",
        "### How to Use:\n",
        "1. Ensure you have the necessary CSV files containing customer interactions, purchase history, and product details.\n",
        "2. Run the script to obtain recommendations for a specific user.\n",
        "3. Check the printed output for the top recommended products.\n",
        "\n",
        "### Additional Notes:\n",
        "- Adjust the number of latent factors (`k`) in SVD to control the model's complexity and performance.\n",
        "- The provided `user_id` should correspond to the IDs used in the purchase history dataset.\n"
      ],
      "metadata": {
        "id": "atHtXCxQo2QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ddY1SLw3Xc2",
        "outputId": "20da8a50-64e4-4644-d635-e60768227246"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b80IhBVY3GW8",
        "outputId": "6f31ad9d-44cb-4e80-e1be-0b81d332c303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user 100\n",
            "     Product ID                         Category       Price  Ratings  \\\n",
            "250         251                  Books and Media    5.894098      5.0   \n",
            "636         637  Apparel and Fashion Accessories  133.945918      4.6   \n",
            "697         698      Home and Kitchen Appliances  559.541235      4.9   \n",
            "928         929                   Toys and Games  277.117038      5.0   \n",
            "951         952                  Books and Media   45.681721      4.9   \n",
            "\n",
            "                                          Product Icon  \n",
            "250  https://raw.githubusercontent.com/reckn/super-...  \n",
            "636  https://raw.githubusercontent.com/reckn/super-...  \n",
            "697  https://raw.githubusercontent.com/reckn/super-...  \n",
            "928  https://raw.githubusercontent.com/reckn/super-...  \n",
            "951  https://raw.githubusercontent.com/reckn/super-...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# Load datasets\n",
        "interactions = pd.read_csv('/content/drive/MyDrive/fair_dataset/customer_interactions_synthetic.csv')\n",
        "purchase_history = pd.read_csv('/content/drive/MyDrive/fair_dataset/purchase_history_synthetic.csv')\n",
        "product_details = pd.read_csv('/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv')\n",
        "\n",
        "# Preprocess data\n",
        "# Merge datasets to create a unified dataset\n",
        "purchase_history = pd.merge(purchase_history, product_details, on='Product ID')\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = pd.pivot_table(purchase_history, values='Ratings', index='Customer ID', columns='Product ID', fill_value=0)\n",
        "\n",
        "# Convert the user-item matrix to a sparse matrix\n",
        "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
        "\n",
        "# Decompose the matrix using SVD\n",
        "U, sigma, Vt = svds(user_item_sparse, k=50)  # k is the number of latent factors\n",
        "\n",
        "# Convert sigma to diagonal matrix form\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Make predictions\n",
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "\n",
        "# Convert the reconstructed matrix back to a DataFrame\n",
        "preds_df = pd.DataFrame(all_user_predicted_ratings, columns=user_item_matrix.columns)\n",
        "\n",
        "# Function to recommend top products for a given user\n",
        "def recommend_products(user_id, num_recommendations=5):\n",
        "    # Get the row corresponding to the user\n",
        "    user_row_number = user_id - 1\n",
        "    sorted_user_predictions = preds_df.iloc[user_row_number].sort_values(ascending=False)\n",
        "\n",
        "    # Get the user's purchase history\n",
        "    user_history = purchase_history[purchase_history['Customer ID'] == user_id]['Product ID']\n",
        "\n",
        "    # Filter out products the user has already purchased\n",
        "    recommendations = sorted_user_predictions.drop(user_history, errors='ignore')\n",
        "\n",
        "    # Get top recommendations\n",
        "    top_recommendations = recommendations.head(num_recommendations)\n",
        "    top_product_details = product_details[product_details['Product ID'].isin(top_recommendations.index)]\n",
        "\n",
        "    return top_product_details[['Product ID', 'Category', 'Price', 'Ratings', 'Product Icon']]\n",
        "\n",
        "# Example: Get recommendations for a specific user (e.g., user ID 100)\n",
        "user_id = 100\n",
        "recommendations = recommend_products(user_id)\n",
        "print(\"Top 5 recommendations for user\", user_id)\n",
        "print(recommendations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation Model Serialization Documentation\n",
        "\n",
        "### Overview\n",
        "This code serializes a recommendation model for future use. It loads datasets, preprocesses the data, performs matrix factorization using Singular Value Decomposition (SVD), makes predictions, and then saves the predictions DataFrame to a file using pickle.\n",
        "\n",
        "### Steps Explained:\n",
        "\n",
        "#### 1. Load Datasets\n",
        "   - **Purpose**: Load customer interactions, purchase history, and product details datasets from CSV files.\n",
        "   - **Inputs**: None.\n",
        "   - **Output**: DataFrames `interactions`, `purchase_history`, and `product_details`.\n",
        "\n",
        "#### 2. Preprocess Data\n",
        "   - **Purpose**: Merge datasets to create a unified dataset and prepare it for matrix factorization.\n",
        "   - **Inputs**: Purchase history and product details DataFrames.\n",
        "   - **Output**: User-item matrix (`user_item_matrix`) and sparse matrix representation (`user_item_sparse`).\n",
        "\n",
        "#### 3. Decompose Matrix using SVD\n",
        "   - **Purpose**: Decompose the user-item matrix using Singular Value Decomposition (SVD) to extract latent factors.\n",
        "   - **Inputs**: Sparse user-item matrix and the number of latent factors (`k`).\n",
        "   - **Output**: Decomposed matrices `U`, `sigma`, and `Vt`.\n",
        "\n",
        "#### 4. Make Predictions\n",
        "   - **Purpose**: Reconstruct the user-item matrix using the decomposed matrices to make predictions.\n",
        "   - **Inputs**: Decomposed matrices `U`, `sigma`, and `Vt`.\n",
        "   - **Output**: Predicted ratings for all user-item interactions.\n",
        "\n",
        "#### 5. Save Predictions\n",
        "   - **Purpose**: Serialize the predictions DataFrame using pickle for future use.\n",
        "   - **Inputs**: Predictions DataFrame.\n",
        "   - **Output**: Serialized file (`preds_df.pkl`).\n",
        "\n",
        "### How to Use:\n",
        "1. Run the script to perform matrix factorization and generate predictions.\n",
        "2. Check for the serialized file `preds_df.pkl`, which contains the predictions DataFrame, for future use.\n",
        "\n",
        "### Additional Notes:\n",
        "- Serialization allows you to save the model state, enabling reuse without retraining.\n",
        "- Remember to load the serialized file appropriately when needed.\n"
      ],
      "metadata": {
        "id": "-JwSpKEEpI5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "import pickle\n",
        "\n",
        "# Load datasets\n",
        "interactions = pd.read_csv('/content/drive/MyDrive/fair_dataset/customer_interactions_synthetic.csv')\n",
        "purchase_history = pd.read_csv('/content/drive/MyDrive/fair_dataset/purchase_history_synthetic.csv')\n",
        "product_details = pd.read_csv('/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv')\n",
        "\n",
        "# Preprocess data\n",
        "# Merge datasets to create a unified dataset\n",
        "purchase_history = pd.merge(purchase_history, product_details, on='Product ID')\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = pd.pivot_table(purchase_history, values='Ratings', index='Customer ID', columns='Product ID', fill_value=0)\n",
        "\n",
        "# Convert the user-item matrix to a sparse matrix\n",
        "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
        "\n",
        "# Decompose the matrix using SVD\n",
        "U, sigma, Vt = svds(user_item_sparse, k=50)  # k is the number of latent factors\n",
        "\n",
        "# Convert sigma to diagonal matrix form\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Make predictions\n",
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "\n",
        "# Convert the reconstructed matrix back to a DataFrame\n",
        "preds_df = pd.DataFrame(all_user_predicted_ratings, columns=user_item_matrix.columns)\n",
        "\n",
        "# Save preds_df to a file\n",
        "with open('preds_df.pkl', 'wb') as f:\n",
        "    pickle.dump(preds_df, f)"
      ],
      "metadata": {
        "id": "fyN0gnCBz4iP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product Recommendation Documentation\n",
        "\n",
        "### Overview\n",
        "This code provides product recommendations for a given user based on a previously trained recommendation model. It loads datasets, including customer interactions, purchase history, and product details, and utilizes a serialized prediction DataFrame (`preds_df.pkl`) to make recommendations.\n",
        "\n",
        "### Function Explained:\n",
        "\n",
        "#### 1. `recommend_products(user_id, num_recommendations=5)`\n",
        "   - **Purpose**: Generate top product recommendations for a given user based on the serialized predictions DataFrame.\n",
        "   - **Inputs**:\n",
        "       - `user_id` (int): ID of the user for whom recommendations are generated.\n",
        "       - `num_recommendations` (int): Number of recommendations to generate (default is 5).\n",
        "   - **Output**: DataFrame containing top recommended products for the user.\n",
        "\n",
        "### How to Use:\n",
        "1. Ensure you have the necessary CSV files containing customer interactions, purchase history, and product details.\n",
        "2. Run the script to obtain recommendations for a specific user (e.g., user ID 100).\n",
        "3. Check the printed output for the top recommended products.\n",
        "\n",
        "### Additional Notes:\n",
        "- The serialized predictions DataFrame (`preds_df.pkl`) must be available in the same directory as the script.\n",
        "- Adjust the number of recommendations to generate by modifying the `num_recommendations` parameter.\n"
      ],
      "metadata": {
        "id": "P6AJTnmvpXkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "import pickle\n",
        "\n",
        "# Load datasets\n",
        "interactions = pd.read_csv('/content/drive/MyDrive/fair_dataset/customer_interactions_synthetic.csv')\n",
        "purchase_history = pd.read_csv('/content/drive/MyDrive/fair_dataset/purchase_history_synthetic.csv')\n",
        "product_details = pd.read_csv('/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv')\n",
        "\n",
        "# Function to load preds_df and recommend top products for a given user\n",
        "def recommend_products(user_id, num_recommendations=5):\n",
        "    # Load preds_df\n",
        "    with open('preds_df.pkl', 'rb') as f:\n",
        "        preds_df = pickle.load(f)\n",
        "\n",
        "    # Get the row corresponding to the user\n",
        "    user_row_number = user_id - 1\n",
        "    sorted_user_predictions = preds_df.iloc[user_row_number].sort_values(ascending=False)\n",
        "\n",
        "    # Get the user's purchase history\n",
        "    user_history = purchase_history[purchase_history['Customer ID'] == user_id]['Product ID']\n",
        "\n",
        "    # Filter out products the user has already purchased\n",
        "    recommendations = sorted_user_predictions.drop(user_history, errors='ignore')\n",
        "\n",
        "    # Get top recommendations\n",
        "    top_recommendations = recommendations.head(num_recommendations)\n",
        "    top_product_details = product_details[product_details['Product ID'].isin(top_recommendations.index)]\n",
        "\n",
        "    return top_product_details[['Product ID', 'Category', 'Price', 'Ratings', 'Product Icon']]\n",
        "\n",
        "# Example: Get recommendations for a specific user (e.g., user ID 100)\n",
        "user_id = 100\n",
        "recommendations = recommend_products(user_id)\n",
        "print(\"Top 5 recommendations for user\", user_id)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0YrLRuN0Ble",
        "outputId": "f69df5ed-f3c1-4b61-d716-743fe39b66d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user 100\n",
            "     Product ID                         Category       Price  Ratings  \\\n",
            "250         251                  Books and Media    5.894098      5.0   \n",
            "636         637  Apparel and Fashion Accessories  133.945918      4.6   \n",
            "697         698      Home and Kitchen Appliances  559.541235      4.9   \n",
            "928         929                   Toys and Games  277.117038      5.0   \n",
            "951         952                  Books and Media   45.681721      4.9   \n",
            "\n",
            "                                          Product Icon  \n",
            "250  https://raw.githubusercontent.com/reckn/super-...  \n",
            "636  https://raw.githubusercontent.com/reckn/super-...  \n",
            "697  https://raw.githubusercontent.com/reckn/super-...  \n",
            "928  https://raw.githubusercontent.com/reckn/super-...  \n",
            "951  https://raw.githubusercontent.com/reckn/super-...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Miscellaneous"
      ],
      "metadata": {
        "id": "F7rHThAbpk0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# Load datasets\n",
        "interactions = pd.read_csv('/content/drive/MyDrive/fair_dataset/customer_interactions_synthetic.csv')\n",
        "purchase_history = pd.read_csv('/content/drive/MyDrive/fair_dataset/purchase_history_synthetic.csv')\n",
        "product_details = pd.read_csv('/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv')\n",
        "\n",
        "# Merge datasets to create a unified dataset\n",
        "purchase_history = pd.merge(purchase_history, product_details, on='Product ID')\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = pd.pivot_table(purchase_history, values='Ratings', index='Customer ID', columns='Product ID', fill_value=0)\n",
        "\n",
        "# Convert the user-item matrix to a sparse matrix\n",
        "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
        "\n",
        "# Decompose the matrix using SVD\n",
        "U, sigma, Vt = svds(user_item_sparse, k=50)  # k is the number of latent factors\n",
        "\n",
        "# Convert sigma to diagonal matrix form\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Make predictions\n",
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "\n",
        "# Get the customer IDs from the user_item_matrix\n",
        "customer_ids = user_item_matrix.index\n",
        "\n",
        "# Create a mapping dictionary from customer IDs to row indices\n",
        "id_to_index_mapping = {customer_id: idx for idx, customer_id in enumerate(customer_ids)}\n",
        "\n",
        "# Function to recommend top products for a given user\n",
        "def recommend_products(user_id, num_recommendations=5):\n",
        "    # Get the corresponding index for the given user_id\n",
        "    svd_index = id_to_index_mapping.get(user_id)\n",
        "    if svd_index is None:\n",
        "        print(\"User ID not found in the mapping dictionary.\")\n",
        "        return None\n",
        "\n",
        "    # Retrieve predicted ratings for the user\n",
        "    user_ratings = all_user_predicted_ratings[svd_index]\n",
        "\n",
        "    # Get the user's purchase history\n",
        "    user_history = user_item_matrix.iloc[svd_index]\n",
        "\n",
        "    # Set already purchased products to zero so they are not recommended\n",
        "    user_ratings[user_history > 0] = 0\n",
        "\n",
        "    # Get indices of top recommendations\n",
        "    top_indices = np.argsort(user_ratings)[::-1][:num_recommendations]\n",
        "\n",
        "    # Get product details for top recommendations\n",
        "    top_product_details = product_details.iloc[top_indices]\n",
        "\n",
        "    return top_product_details[['Product ID', 'Category', 'Price', 'Ratings', 'Product Icon']]\n",
        "\n",
        "# Example usage\n",
        "recommendations = recommend_products(user_id=12345, num_recommendations=5)\n",
        "print(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNGw5-r1VUM2",
        "outputId": "b7eab1b6-c410-4cb4-b19c-5049be3f6aaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID not found in the mapping dictionary.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save and load model so that we do not need to train the model again each time we run the program"
      ],
      "metadata": {
        "id": "4LUCbXDygq6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
        "from scipy.sparse.linalg import svds\n",
        "import pickle\n",
        "\n",
        "# File paths\n",
        "interactions_path = '/content/drive/MyDrive/fair_dataset/customer_interactions_synthetic.csv'\n",
        "purchase_history_path = '/content/drive/MyDrive/fair_dataset/purchase_history_synthetic.csv'\n",
        "product_details_path = '/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv'\n",
        "\n",
        "# Function to load datasets\n",
        "def load_datasets(interactions_path, purchase_history_path, product_details_path):\n",
        "    interactions = pd.read_csv(interactions_path)\n",
        "    purchase_history = pd.read_csv(purchase_history_path)\n",
        "    product_details = pd.read_csv(product_details_path)\n",
        "    return interactions, purchase_history, product_details\n",
        "\n",
        "# Function to merge datasets\n",
        "def merge_datasets(purchase_history, product_details):\n",
        "    merged_data = pd.merge(purchase_history, product_details, on='Product ID')\n",
        "    return merged_data\n",
        "\n",
        "# Function to create user-item matrix using groupby\n",
        "def create_user_item_matrix(data):\n",
        "    user_item_matrix = data.groupby(['Customer ID', 'Product ID'])['Ratings'].max().unstack(fill_value=0)\n",
        "    return user_item_matrix\n",
        "\n",
        "# Function to convert user-item matrix to sparse matrix\n",
        "def convert_to_sparse_matrix(user_item_matrix):\n",
        "    user_item_sparse = csr_matrix(user_item_matrix.values)\n",
        "    return user_item_sparse\n",
        "\n",
        "# Function to perform SVD decomposition\n",
        "def perform_svd(user_item_sparse, k=50):\n",
        "    U, sigma, Vt = svds(user_item_sparse, k=k)\n",
        "    sigma = np.diag(sigma)\n",
        "    return U, sigma, Vt\n",
        "\n",
        "# Function to save SVD results and mapping dictionary\n",
        "def save_results(U, sigma, Vt, id_to_index_mapping):\n",
        "    np.save('U.npy', U)\n",
        "    np.save('sigma.npy', sigma)\n",
        "    np.save('Vt.npy', Vt)\n",
        "    with open('id_to_index_mapping.pkl', 'wb') as f:\n",
        "        pickle.dump(id_to_index_mapping, f)\n",
        "\n",
        "# Function to load SVD results and mapping dictionary\n",
        "def load_results():\n",
        "    U = np.load('U.npy')\n",
        "    sigma = np.load('sigma.npy')\n",
        "    Vt = np.load('Vt.npy')\n",
        "    with open('id_to_index_mapping.pkl', 'rb') as f:\n",
        "        id_to_index_mapping = pickle.load(f)\n",
        "    return U, sigma, Vt, id_to_index_mapping\n",
        "\n",
        "# Function to recommend top products for a given user\n",
        "def recommend_products(user_id, all_user_predicted_ratings, user_item_matrix, product_details, id_to_index_mapping, num_recommendations=5):\n",
        "    svd_index = id_to_index_mapping.get(user_id)\n",
        "    if svd_index is None:\n",
        "        print(\"User ID not found in the mapping dictionary.\")\n",
        "        return None\n",
        "\n",
        "    user_ratings = all_user_predicted_ratings[svd_index]\n",
        "    user_history = user_item_matrix.iloc[svd_index]\n",
        "    user_ratings[user_history > 0] = 0\n",
        "\n",
        "    top_indices = np.argsort(user_ratings)[::-1][:num_recommendations]\n",
        "    top_product_details = product_details.iloc[top_indices]\n",
        "\n",
        "    return top_product_details[['Product Icon']]\n",
        "\n",
        "# Load datasets\n",
        "interactions, purchase_history, product_details = load_datasets(interactions_path, purchase_history_path, product_details_path)\n",
        "\n",
        "# Merge datasets\n",
        "merged_data = merge_datasets(purchase_history, product_details)\n",
        "\n",
        "# Create user-item matrix\n",
        "user_item_matrix = create_user_item_matrix(merged_data)\n",
        "\n",
        "# Convert user-item matrix to sparse matrix\n",
        "user_item_sparse = convert_to_sparse_matrix(user_item_matrix)\n",
        "\n",
        "try:\n",
        "    # Load precomputed SVD results and mapping dictionary\n",
        "    U, sigma, Vt, id_to_index_mapping = load_results()\n",
        "    print(\"Loaded precomputed SVD results and mapping dictionary.\")\n",
        "except FileNotFoundError:\n",
        "    # Perform SVD decomposition\n",
        "    U, sigma, Vt = perform_svd(user_item_sparse)\n",
        "\n",
        "    # Create mapping dictionary from customer IDs to row indices\n",
        "    customer_ids = user_item_matrix.index\n",
        "    id_to_index_mapping = {customer_id: idx for idx, customer_id in enumerate(customer_ids)}\n",
        "\n",
        "    # Save SVD results and mapping dictionary\n",
        "    save_results(U, sigma, Vt, id_to_index_mapping)\n",
        "    print(\"Computed SVD results and created mapping dictionary.\")\n",
        "\n",
        "# Make predictions\n",
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "\n",
        "# Example usage\n",
        "recommendations = recommend_products(user_id=4126209, all_user_predicted_ratings=all_user_predicted_ratings, user_item_matrix=user_item_matrix, product_details=product_details, id_to_index_mapping=id_to_index_mapping, num_recommendations=5)\n",
        "print(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKSF6LU7cILa",
        "outputId": "e24de17c-398a-4a79-a960-5206bd336f1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed SVD results and created mapping dictionary.\n",
            "User ID not found in the mapping dictionary.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(user_item_matrix.values, all_user_predicted_ratings))\n",
        "\n",
        "# Print RMSE\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgJ_Sp3CX2Q1",
        "outputId": "3d1a2788-4cca-49e3-c9f1-9a841d5873db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.502364716890839\n"
          ]
        }
      ]
    }
  ]
}