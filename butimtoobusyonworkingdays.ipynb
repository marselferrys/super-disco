{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "0dHn-i-inCOd",
        "PCiEPvwxna4U",
        "OG1NXawIn7mv"
      ],
      "mount_file_id": "1x9aJfJsJ0e54yV3IN86Pwkiv0ZFAJEjY",
      "authorship_tag": "ABX9TyN6CJ6EdJAh+alAGyul1hVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reckn/super-disco/blob/main/butimtoobusyonworkingdays.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation System Collaborative\n",
        "\n",
        "### Overview\n",
        "This code is all about recommendation systems! 🎉 It helps you build a recommendation model based on customer interactions and purchase history.\n",
        "\n",
        "### Functions Explained:\n",
        "\n",
        "#### 1. `load_data(file_path)`\n",
        "   - **Purpose**: Loads data from CSV files.\n",
        "   - **Input**: `file_path` - Path to the directory containing CSV files.\n",
        "   - **Output**: Three DataFrames: `interactions`, `purchase_history`, and `product_details`.\n",
        "   \n",
        "#### 2. `preprocess_data(purchase_history, product_details, save_path)`\n",
        "   - **Purpose**: Prepares the purchase history data for modeling.\n",
        "   - **Inputs**:\n",
        "       - `purchase_history`: DataFrame containing purchase history.\n",
        "       - `product_details`: DataFrame containing product details.\n",
        "       - `save_path`: Path to save the preprocessed dataset.\n",
        "   - **Output**: Preprocessed purchase history DataFrame.\n",
        "\n",
        "#### 3. `build_interaction_matrix(purchase_history, save_path)`\n",
        "   - **Purpose**: Constructs an interaction matrix from purchase history data.\n",
        "   - **Inputs**:\n",
        "       - `purchase_history`: DataFrame containing purchase history.\n",
        "       - `save_path`: Path to save the sparse interaction matrix.\n",
        "   - **Output**: Sparse interaction matrix.\n",
        "\n",
        "#### 4. `train_model(interactions_matrix, epochs=10)`\n",
        "   - **Purpose**: Trains a LightFM model using the interaction matrix.\n",
        "   - **Inputs**:\n",
        "       - `interactions_matrix`: Sparse interaction matrix.\n",
        "       - `epochs`: Number of training iterations (default is 10).\n",
        "   - **Output**: Trained LightFM model.\n",
        "\n",
        "#### 5. `save_model(model, save_path)`\n",
        "   - **Purpose**: Saves the trained LightFM model to disk.\n",
        "   - **Inputs**:\n",
        "       - `model`: Trained LightFM model.\n",
        "       - `save_path`: Path to save the trained model.\n",
        "\n",
        "#### 6. `main()`\n",
        "   - **Purpose**: Orchestrates the entire process of data loading, preprocessing, model training, and saving.\n",
        "   - **Steps**:\n",
        "       1. Load data.\n",
        "       2. Preprocess data.\n",
        "       3. Build interaction matrix.\n",
        "       4. Train model.\n",
        "       5. Save model.\n",
        "\n",
        "### How to Use:\n",
        "1. Make sure you have CSV files containing customer interactions, purchase history, and product details.\n",
        "2. Set the paths for your data files and where you want to save the results.\n",
        "3. Run `main()` and let the magic happen! 🚀\n",
        "\n",
        "### Additional Notes:\n",
        "- If you need to use the interaction matrix or purchase history again, there are commented-out lines to help you reload them.\n",
        "- Feel free to tweak the number of training epochs for the model by changing the `epochs` parameter in `train_model()`.\n"
      ],
      "metadata": {
        "id": "0dHn-i-inCOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNc6vMiA55d1",
        "outputId": "c168160a-412e-4b67-ce6e-09447c1827de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faOhN9YH6F5t",
        "outputId": "3b88f655-4a92-4bed-d262-1bc8a71f076e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.3.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=808330 sha256=d837701c01f78934c8a58c2cfa5d10db98f5da4e114472cbc84aab8c71c9eda9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.sparse import save_npz, load_npz\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "import pickle\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load data from CSV files.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the directory containing CSV files.\n",
        "\n",
        "    Returns:\n",
        "    - interactions (DataFrame): DataFrame containing customer interactions.\n",
        "    - purchase_history (DataFrame): DataFrame containing purchase history.\n",
        "    - product_details (DataFrame): DataFrame containing product details.\n",
        "    \"\"\"\n",
        "    interactions = pd.read_csv(file_path + 'customer_interactions_synthetic.csv')\n",
        "    purchase_history = pd.read_csv(file_path + 'purchase_history_synthetic.csv')\n",
        "    product_details = pd.read_csv(file_path + 'product_details_synthetic.csv')\n",
        "    return interactions, purchase_history, product_details\n",
        "\n",
        "def preprocess_data(purchase_history, product_details, save_path):\n",
        "    \"\"\"\n",
        "    Preprocess purchase history data.\n",
        "\n",
        "    Args:\n",
        "    - purchase_history (DataFrame): DataFrame containing purchase history.\n",
        "    - product_details (DataFrame): DataFrame containing product details.\n",
        "    - save_path (str): Path to save preprocessed dataset.\n",
        "\n",
        "    Returns:\n",
        "    - purchase_history (DataFrame): Preprocessed purchase history DataFrame.\n",
        "    \"\"\"\n",
        "    purchase_history = pd.merge(purchase_history, product_details, on='Product ID')\n",
        "    purchase_history.to_csv(save_path + 'preprocessed_dataset.csv', index=False)\n",
        "    return purchase_history\n",
        "\n",
        "def build_interaction_matrix(purchase_history, save_path):\n",
        "    \"\"\"\n",
        "    Build interaction matrix from purchase history data.\n",
        "\n",
        "    Args:\n",
        "    - purchase_history (DataFrame): DataFrame containing purchase history.\n",
        "    - save_path (str): Path to save sparse interaction matrix.\n",
        "\n",
        "    Returns:\n",
        "    - interactions_matrix (sparse matrix): Sparse interaction matrix.\n",
        "    \"\"\"\n",
        "    dataset = Dataset()\n",
        "    dataset.fit(users=purchase_history['Customer ID'], items=purchase_history['Product ID'])\n",
        "    interactions_matrix, _ = dataset.build_interactions([(x['Customer ID'], x['Product ID'], 1) for _, x in purchase_history.iterrows()])\n",
        "    save_npz(save_path + 'interactions_matrix_sparse.npz', interactions_matrix)\n",
        "    return interactions_matrix\n",
        "\n",
        "def train_model(interactions_matrix, epochs=10):\n",
        "    \"\"\"\n",
        "    Train LightFM model.\n",
        "\n",
        "    Args:\n",
        "    - interactions_matrix (sparse matrix): Sparse interaction matrix.\n",
        "    - epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "    - model (LightFM model): Trained LightFM model.\n",
        "    \"\"\"\n",
        "    train_interactions, _ = random_train_test_split(interactions_matrix, test_percentage=0.2, random_state=42)\n",
        "    model = LightFM(loss='warp')\n",
        "    model.fit(train_interactions, epochs=epochs)\n",
        "    return model\n",
        "\n",
        "def save_model(model, save_path):\n",
        "    \"\"\"\n",
        "    Save trained LightFM model to disk.\n",
        "\n",
        "    Args:\n",
        "    - model (LightFM model): Trained LightFM model.\n",
        "    - save_path (str): Path to save trained model.\n",
        "    \"\"\"\n",
        "    with open(save_path + 'lightfm_model.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate data loading, preprocessing, model training, and saving.\n",
        "    \"\"\"\n",
        "    file_path = '/content/drive/MyDrive/fair_dataset/'\n",
        "    save_path = '/content/drive/MyDrive/fair_dataset/'\n",
        "\n",
        "    # Load data\n",
        "    interactions, purchase_history, product_details = load_data(file_path)\n",
        "\n",
        "    # Preprocess data\n",
        "    purchase_history = preprocess_data(purchase_history, product_details, save_path)\n",
        "\n",
        "    # Build interaction matrix\n",
        "    interactions_matrix = build_interaction_matrix(purchase_history, save_path)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(interactions_matrix)\n",
        "\n",
        "    # Save model\n",
        "    save_model(model, save_path)\n",
        "\n",
        "    # Additional steps\n",
        "    # If needed, load interaction matrix and purchase history again\n",
        "    # interactions_matrix = load_npz(save_path + 'interactions_matrix_sparse.npz')\n",
        "    # purchase_history = pd.read_csv(save_path + 'preprocessed_dataset.csv')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "sXVSU8_dDu3S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Recommendation System Documentation\n",
        "\n",
        "### Overview\n",
        "This code evaluates the performance of a recommendation system built using LightFM. It assesses the model's ability to predict user-item interactions and provides evaluation metrics such as RMSE (Root Mean Squared Error) and AUC (Area Under the Curve) scores.\n",
        "\n",
        "### Functions Explained:\n",
        "\n",
        "#### 1. Load Data and Model\n",
        "   - **Purpose**: Load preprocessed dataset and trained model.\n",
        "   - **Inputs**: None.\n",
        "   - **Output**: Loaded `purchase_history` DataFrame and trained `model`.\n",
        "\n",
        "#### 2. Split Data\n",
        "   - **Purpose**: Split interactions matrix into train and test sets.\n",
        "   - **Inputs**: None.\n",
        "   - **Output**: `train_interactions` and `test_interactions` sparse matrices.\n",
        "\n",
        "#### 3. Predict Scores\n",
        "   - **Purpose**: Predict preference scores for train and test sets using the trained model.\n",
        "   - **Inputs**: None.\n",
        "   - **Output**: Predicted scores for train and test sets.\n",
        "\n",
        "#### 4. Compute RMSE (Root Mean Squared Error)\n",
        "   - **Purpose**: Calculate RMSE for train and test sets to evaluate model performance.\n",
        "   - **Inputs**: Predicted scores and actual interactions data.\n",
        "   - **Output**: RMSE for train and test sets.\n",
        "\n",
        "#### 5. Compute AUC (Area Under the Curve)\n",
        "   - **Purpose**: Calculate AUC score for train and test sets to evaluate model performance.\n",
        "   - **Inputs**: Trained model and interaction matrices.\n",
        "   - **Output**: AUC score for train and test sets.\n",
        "\n",
        "#### 6. Print Evaluation Metrics\n",
        "   - **Purpose**: Output evaluation metrics (RMSE and AUC) for train and test sets.\n",
        "   - **Inputs**: RMSE and AUC scores.\n",
        "   - **Output**: Printed evaluation metrics.\n",
        "\n",
        "### How to Use:\n",
        "1. Ensure you have the preprocessed dataset, trained model, and interaction matrix saved.\n",
        "2. Run the script to evaluate the model's performance.\n",
        "3. Check the printed RMSE and AUC scores for train and test sets.\n",
        "\n",
        "### Additional Notes:\n",
        "- RMSE measures the difference between predicted and actual values, with lower values indicating better performance.\n",
        "- AUC measures the model's ability to discriminate between positive and negative interactions, with higher values indicating better performance.\n",
        "- Adjust the test percentage in data splitting by modifying the `test_percentage` parameter in `random_train_test_split`.\n"
      ],
      "metadata": {
        "id": "PCiEPvwxna4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.evaluation import auc_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle\n",
        "from scipy.sparse import load_npz\n",
        "\n",
        "# Load preprocessed dataset\n",
        "purchase_history = pd.read_csv('/content/drive/MyDrive/fair_dataset/preprocessed_dataset.csv')\n",
        "\n",
        "# Load the sparse matrix containing user-item interactions\n",
        "interactions_matrix = load_npz('/content/drive/MyDrive/fair_dataset/interactions_matrix_sparse.npz')\n",
        "\n",
        "# Load trained model from pickle file\n",
        "with open('/content/drive/MyDrive/fair_dataset/lightfm_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Split data into train and test sets\n",
        "# Randomly split interactions matrix into train and test sets\n",
        "train_interactions, test_interactions = random_train_test_split(interactions_matrix, test_percentage=0.2, random_state=42)\n",
        "\n",
        "# Predict scores for training and test sets\n",
        "# Predict the preference scores for interactions in both train and test sets using the trained model\n",
        "train_scores = model.predict(train_interactions.row, train_interactions.col)\n",
        "test_scores = model.predict(test_interactions.row, test_interactions.col)\n",
        "\n",
        "# Compute RMSE (Root Mean Squared Error)\n",
        "# Calculate RMSE for both train and test sets to evaluate the model's performance\n",
        "train_rmse = np.sqrt(mean_squared_error(train_interactions.data, train_scores))\n",
        "test_rmse = np.sqrt(mean_squared_error(test_interactions.data, test_scores))\n",
        "\n",
        "# Compute AUC (Area Under the Curve)\n",
        "# Calculate AUC score for both train and test sets to evaluate the model's performance\n",
        "train_auc = auc_score(model, train_interactions).mean()\n",
        "test_auc = auc_score(model, test_interactions).mean()\n",
        "\n",
        "# Print RMSE and AUC\n",
        "# Output the evaluation metrics: RMSE and AUC scores for both train and test sets\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)\n",
        "print(\"Train AUC Score:\", train_auc)\n",
        "print(\"Test AUC Score:\", test_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ul7g-pPI3dP",
        "outputId": "6841f2a1-1c7f-4615-953f-b01ec4676e75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 2.5414734892967394\n",
            "Test RMSE: 2.868328441671248\n",
            "Train AUC Score: 0.67846113\n",
            "Test AUC Score: 0.49914727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation Generation Documentation\n",
        "\n",
        "### Overview\n",
        "This code generates personalized product recommendations for a given user using a trained LightFM model. It utilizes user-item interaction data and product details to recommend products based on the user's preferences.\n",
        "\n",
        "### Functions Explained:\n",
        "\n",
        "#### 1. `load_model(model_path)`\n",
        "   - **Purpose**: Load a trained LightFM model from a pickle file.\n",
        "   - **Inputs**:\n",
        "       - `model_path` (str): Path to the pickle file containing the trained model.\n",
        "   - **Output**: Trained LightFM model.\n",
        "\n",
        "#### 2. `recommend_products(model, user_id, interactions_matrix, product_details, num_recommendations=5)`\n",
        "   - **Purpose**: Generate recommendations for a given user.\n",
        "   - **Inputs**:\n",
        "       - `model` (LightFM): Trained LightFM model.\n",
        "       - `user_id` (int): ID of the user for whom recommendations are generated.\n",
        "       - `interactions_matrix` (sparse matrix): Sparse matrix representing user-item interactions.\n",
        "       - `product_details` (DataFrame): DataFrame containing product details.\n",
        "       - `num_recommendations` (int): Number of recommendations to generate (default is 5).\n",
        "   - **Output**: DataFrames containing the user's known interactions (`known_positives`) and top recommended products (`top_items`).\n",
        "\n",
        "### How to Use:\n",
        "1. Ensure you have the trained LightFM model, interactions matrix, and product details dataset saved.\n",
        "2. Specify the user ID for whom recommendations will be generated (`user_id`).\n",
        "3. Run the script to obtain recommendations.\n",
        "4. Check the printed outputs for the user's known interactions and top recommended products.\n",
        "\n",
        "### Additional Notes:\n",
        "- Adjust the number of recommendations to generate by modifying the `num_recommendations` parameter in `recommend_products`.\n",
        "- The provided `user_id` should correspond to the IDs used in the interactions matrix.\n"
      ],
      "metadata": {
        "id": "OG1NXawIn7mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from scipy.sparse import load_npz\n",
        "import pickle\n",
        "\n",
        "def load_model(model_path):\n",
        "    \"\"\"\n",
        "    Load a trained LightFM model from a pickle file.\n",
        "\n",
        "    Args:\n",
        "    - model_path (str): Path to the pickle file containing the trained model.\n",
        "\n",
        "    Returns:\n",
        "    - model (LightFM): Trained LightFM model.\n",
        "    \"\"\"\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model\n",
        "\n",
        "def recommend_products(model, user_id, interactions_matrix, product_details, num_recommendations=5):\n",
        "    \"\"\"\n",
        "    Generate recommendations for a given user.\n",
        "\n",
        "    Args:\n",
        "    - model (LightFM): Trained LightFM model.\n",
        "    - user_id (int): ID of the user for whom recommendations are generated.\n",
        "    - interactions_matrix (sparse matrix): Sparse matrix representing user-item interactions.\n",
        "    - product_details (DataFrame): DataFrame containing product details.\n",
        "    - num_recommendations (int): Number of recommendations to generate.\n",
        "\n",
        "    Returns:\n",
        "    - known_positives (DataFrame): DataFrame containing the user's known interactions.\n",
        "    - top_items (DataFrame): DataFrame containing the top recommended products.\n",
        "    \"\"\"\n",
        "    # Get the user's known interactions\n",
        "    known_positives = product_details.loc[interactions_matrix.tocsr()[user_id].indices]\n",
        "\n",
        "    # Predict scores for all products\n",
        "    num_items = interactions_matrix.shape[1]\n",
        "    scores = model.predict(user_id, np.arange(num_items))\n",
        "\n",
        "    # Rank the products based on scores\n",
        "    top_items = product_details.iloc[np.argsort(-scores)][:num_recommendations]\n",
        "\n",
        "    return known_positives, top_items\n",
        "\n",
        "# Load the trained LightFM model\n",
        "model_path = '/content/drive/MyDrive/fair_dataset/lightfm_model.pkl'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load interactions matrix\n",
        "interactions_matrix = load_npz('/content/drive/MyDrive/fair_dataset/interactions_matrix_sparse.npz')\n",
        "\n",
        "# Load product details\n",
        "product_details = pd.read_csv('/content/drive/MyDrive/fair_dataset/product_details_synthetic.csv')\n",
        "\n",
        "# User ID to make recommendations for\n",
        "user_id = 2665  # Please note that the actual user ID != user_id in interactions_matrix, this driving me nuts.\n",
        "\n",
        "# Get recommendations for the user\n",
        "known_positives, top_items = recommend_products(model, user_id, interactions_matrix, product_details)\n",
        "\n",
        "print(\"User's known interactions:\")\n",
        "print(known_positives)\n",
        "\n",
        "print(\"\\nTop recommended products:\")\n",
        "print(top_items)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1JT11xKD_Jm",
        "outputId": "72092b47-961d-432f-86c8-8dc3c57d0f37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User's known interactions:\n",
            "     Product ID                              Category        Price  Ratings  \\\n",
            "10           11           Home and Kitchen Appliances   498.231012      1.9   \n",
            "55           56      Consumer Electronics Accessories   115.233923      4.8   \n",
            "86           87      Consumer Electronics Accessories    21.833070      2.8   \n",
            "157         158           Home and Kitchen Appliances  1931.479308      4.2   \n",
            "188         189       Apparel and Fashion Accessories    48.677301      2.1   \n",
            "196         197     Beauty and Personal Care Products    69.109522      2.6   \n",
            "207         208                           Electronics  3342.564356      4.8   \n",
            "237         238  Sporting Goods and Fitness Equipment   904.035733      3.3   \n",
            "325         326           Home and Kitchen Appliances   319.079902      4.0   \n",
            "380         381      Consumer Electronics Accessories   199.505981      2.8   \n",
            "454         455          Health and Wellness Products    33.911870      3.6   \n",
            "539         540          Health and Wellness Products   412.474597      3.7   \n",
            "589         590                        Toys and Games   205.424146      4.1   \n",
            "613         614          Health and Wellness Products    87.610472      5.0   \n",
            "623         624  Sporting Goods and Fitness Equipment  1052.765187      4.5   \n",
            "697         698           Home and Kitchen Appliances   559.541235      4.9   \n",
            "756         757                        Toys and Games   240.731934      1.6   \n",
            "790         791       Apparel and Fashion Accessories   449.807864      3.1   \n",
            "833         834                          Pet Supplies   201.411417      1.3   \n",
            "877         878                           Electronics  2255.498977      4.9   \n",
            "883         884                           Electronics  3988.595379      4.8   \n",
            "900         901           Home and Kitchen Appliances  1954.432382      3.9   \n",
            "929         930                       Books and Media    29.149978      1.6   \n",
            "940         941          Health and Wellness Products   359.648843      4.8   \n",
            "953         954  Sporting Goods and Fitness Equipment   968.284997      1.1   \n",
            "956         957      Consumer Electronics Accessories   166.071843      1.2   \n",
            "\n",
            "                                          Product Icon  \n",
            "10   https://raw.githubusercontent.com/reckn/super-...  \n",
            "55   https://raw.githubusercontent.com/reckn/super-...  \n",
            "86   https://raw.githubusercontent.com/reckn/super-...  \n",
            "157  https://raw.githubusercontent.com/reckn/super-...  \n",
            "188  https://raw.githubusercontent.com/reckn/super-...  \n",
            "196  https://raw.githubusercontent.com/reckn/super-...  \n",
            "207  https://raw.githubusercontent.com/reckn/super-...  \n",
            "237  https://raw.githubusercontent.com/reckn/super-...  \n",
            "325  https://raw.githubusercontent.com/reckn/super-...  \n",
            "380  https://raw.githubusercontent.com/reckn/super-...  \n",
            "454  https://raw.githubusercontent.com/reckn/super-...  \n",
            "539  https://raw.githubusercontent.com/reckn/super-...  \n",
            "589  https://raw.githubusercontent.com/reckn/super-...  \n",
            "613  https://raw.githubusercontent.com/reckn/super-...  \n",
            "623  https://raw.githubusercontent.com/reckn/super-...  \n",
            "697  https://raw.githubusercontent.com/reckn/super-...  \n",
            "756  https://raw.githubusercontent.com/reckn/super-...  \n",
            "790  https://raw.githubusercontent.com/reckn/super-...  \n",
            "833  https://raw.githubusercontent.com/reckn/super-...  \n",
            "877  https://raw.githubusercontent.com/reckn/super-...  \n",
            "883  https://raw.githubusercontent.com/reckn/super-...  \n",
            "900  https://raw.githubusercontent.com/reckn/super-...  \n",
            "929  https://raw.githubusercontent.com/reckn/super-...  \n",
            "940  https://raw.githubusercontent.com/reckn/super-...  \n",
            "953  https://raw.githubusercontent.com/reckn/super-...  \n",
            "956  https://raw.githubusercontent.com/reckn/super-...  \n",
            "\n",
            "Top recommended products:\n",
            "     Product ID                         Category       Price  Ratings  \\\n",
            "876         877                   Toys and Games  179.595978      3.1   \n",
            "539         540     Health and Wellness Products  412.474597      3.7   \n",
            "940         941     Health and Wellness Products  359.648843      4.8   \n",
            "656         657  Apparel and Fashion Accessories   41.468475      2.3   \n",
            "917         918                  Books and Media   95.964130      2.0   \n",
            "\n",
            "                                          Product Icon  \n",
            "876  https://raw.githubusercontent.com/reckn/super-...  \n",
            "539  https://raw.githubusercontent.com/reckn/super-...  \n",
            "940  https://raw.githubusercontent.com/reckn/super-...  \n",
            "656  https://raw.githubusercontent.com/reckn/super-...  \n",
            "917  https://raw.githubusercontent.com/reckn/super-...  \n"
          ]
        }
      ]
    }
  ]
}